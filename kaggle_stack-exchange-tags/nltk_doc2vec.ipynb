{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19279, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are some Caribbean cruises for October?</td>\n",
       "      <td>&lt;p&gt;My fiancée and I are looking for a good Car...</td>\n",
       "      <td>caribbean cruising vacations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I find a guide that will take me safel...</td>\n",
       "      <td>&lt;p&gt;This was one of our definition questions, b...</td>\n",
       "      <td>guides extreme-tourism amazon-river amazon-jungle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Does Singapore Airlines offer any reward seats...</td>\n",
       "      <td>&lt;p&gt;Singapore Airlines has an all-business clas...</td>\n",
       "      <td>loyalty-programs routes ewr singapore-airlines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the easiest transportation to use thro...</td>\n",
       "      <td>&lt;p&gt;Another definition question that interested...</td>\n",
       "      <td>romania transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How can I visit Antarctica?</td>\n",
       "      <td>&lt;p&gt;A year ago I was reading some magazine, and...</td>\n",
       "      <td>extreme-tourism antarctica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "id                                                      \n",
       "1        What are some Caribbean cruises for October?   \n",
       "2   How can I find a guide that will take me safel...   \n",
       "4   Does Singapore Airlines offer any reward seats...   \n",
       "5   What is the easiest transportation to use thro...   \n",
       "6                         How can I visit Antarctica?   \n",
       "\n",
       "                                              content  \\\n",
       "id                                                      \n",
       "1   <p>My fiancée and I are looking for a good Car...   \n",
       "2   <p>This was one of our definition questions, b...   \n",
       "4   <p>Singapore Airlines has an all-business clas...   \n",
       "5   <p>Another definition question that interested...   \n",
       "6   <p>A year ago I was reading some magazine, and...   \n",
       "\n",
       "                                                 tags  \n",
       "id                                                     \n",
       "1                        caribbean cruising vacations  \n",
       "2   guides extreme-tourism amazon-river amazon-jungle  \n",
       "4   loyalty-programs routes ewr singapore-airlines...  \n",
       "5                              romania transportation  \n",
       "6                          extreme-tourism antarctica  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel = pd.read_csv('data/travel.csv.zip', index_col='id')\n",
    "print(travel.shape)\n",
    "travel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_text(text):\n",
    "    cleantext = re.sub(\"<.*?>\", \"\", text).lower()\n",
    "    splitter = re.compile(\"[^a-zA-Z0-9_\\\\+\\\\-/]\")\n",
    "    words = splitter.split(cleantext)\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    meaningful_words = [w.strip() for w in words if not w in stops]\n",
    "    return \" \".join(filter(None, meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    travel['content'] = travel['content'].apply(prepare_text)\n",
    "    travel['title'] = travel['title'].apply(prepare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_tags(df):\n",
    "    tags = set()\n",
    "    df['tags'].str.split(' ').apply(tags.update)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1645"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prepare_tags(travel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prepare_data(travel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>caribbean cruises october</td>\n",
       "      <td>fianc e looking good caribbean cruise october ...</td>\n",
       "      <td>caribbean cruising vacations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>find guide take safely amazon jungle</td>\n",
       "      <td>one definition questions also one interests pe...</td>\n",
       "      <td>guides extreme-tourism amazon-river amazon-jungle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>singapore airlines offer reward seats ewr-sin ...</td>\n",
       "      <td>singapore airlines all-business class flight e...</td>\n",
       "      <td>loyalty-programs routes ewr singapore-airlines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>easiest transportation use throughout romania ...</td>\n",
       "      <td>another definition question interested easiest...</td>\n",
       "      <td>romania transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>visit antarctica</td>\n",
       "      <td>year ago reading magazine found availability g...</td>\n",
       "      <td>extreme-tourism antarctica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "id                                                      \n",
       "1                           caribbean cruises october   \n",
       "2                find guide take safely amazon jungle   \n",
       "4   singapore airlines offer reward seats ewr-sin ...   \n",
       "5   easiest transportation use throughout romania ...   \n",
       "6                                    visit antarctica   \n",
       "\n",
       "                                              content  \\\n",
       "id                                                      \n",
       "1   fianc e looking good caribbean cruise october ...   \n",
       "2   one definition questions also one interests pe...   \n",
       "4   singapore airlines all-business class flight e...   \n",
       "5   another definition question interested easiest...   \n",
       "6   year ago reading magazine found availability g...   \n",
       "\n",
       "                                                 tags  \n",
       "id                                                     \n",
       "1                        caribbean cruising vacations  \n",
       "2   guides extreme-tourism amazon-river amazon-jungle  \n",
       "4   loyalty-programs routes ewr singapore-airlines...  \n",
       "5                              romania transportation  \n",
       "6                          extreme-tourism antarctica  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = 5000)\n",
    "train_data_features = vectorizer.fit_transform(travel['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 2, 2, 4, 4, 4, 5, 5]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = []\n",
    "for i, row in travel.iterrows():\n",
    "    counts.append(len(row['tags'].split(' ')))\n",
    "\n",
    "counts[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19279.000000\n",
       "mean         3.388869\n",
       "std          1.117759\n",
       "min          1.000000\n",
       "25%          3.000000\n",
       "50%          3.000000\n",
       "75%          4.000000\n",
       "max          5.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(counts, index=travel.index).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for i, row in travel.iterrows():\n",
    "    tags = tokenize_text(row['tags'])\n",
    "    sentences.append(LabeledSentence(words=tokenize_text(row['content']), tags=tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledSentence(words=['fianc', 'looking', 'good', 'caribbean', 'cruise', 'october', 'wondering', 'islands', 'best', 'see', 'cruise', 'line', 'take', 'seems', 'like', 'lot', 'cruises', 'run', 'month', 'due', 'hurricane', 'season', 'looking', 'good', 'options', 'edit', 'travelling', '2012'], tags=['caribbean', 'cruising', 'vacations']),\n",
       " LabeledSentence(words=['one', 'definition', 'questions', 'also', 'one', 'interests', 'personally', 'find', 'guide', 'take', 'safely', 'amazon', 'jungle', 'love', 'explore', 'amazon', 'would', 'attempt', 'without', 'guide', 'least', 'first', 'time', 'prefer', 'guide', 'going', 'ambush', 'anything', 'edit', 'want', 'go', 'anywhere', 'touristy', 'start', 'end', 'points', 'open', 'trip', 'take', 'places', 'likely', 'see', 'travellers', 'tourists', 'definitely', 'require', 'good', 'guide', 'order', 'safe'], tags=['guides', 'extreme-tourism', 'amazon-river', 'amazon-jungle'])]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard_similarity(labels, preds):\n",
    "    lset = set(labels)\n",
    "    pset = set(preds)\n",
    "    return len(lset.intersection(pset)) / len(lset.union(pset))\n",
    "\n",
    "def test(test_sents, model):\n",
    "    results = []\n",
    "    for test_sent in test_sents:\n",
    "        pred_vec = model.infer_vector(test_sent.words)\n",
    "        pred_tags = model.docvecs.most_similar([pred_vec], topn=5)\n",
    "        results.append(jaccard_similarity(test_sent.tags, [p[0] for p in pred_tags]))\n",
    "    return np.array(results)\n",
    "\n",
    "def train(sentences):\n",
    "    model = Doc2Vec(dm=0, size=100, negative=5, hs=0, min_count=2)\n",
    "    model.build_vocab(sentences)\n",
    "    train_sents, test_sents = train_test_split(sentences, test_size=0.2, random_state=42)\n",
    "    alpha = 0.025\n",
    "    min_alpha = 0.001\n",
    "    num_epochs = 40\n",
    "    alpha_delta = (alpha - min_alpha) / num_epochs\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = datetime.datetime.now()\n",
    "        shuffle(train_sents)\n",
    "        model.alpha = alpha\n",
    "        model.min_alpha = alpha\n",
    "        model.train(train_sents)\n",
    "        alpha -= alpha_delta\n",
    "        end_time = datetime.datetime.now()\n",
    "        accuracy = test(test_sents, model).mean()\n",
    "        print(\"Complete epoch {}: {}; Accuracy: {}\".format(epoch, end_time - start_time, accuracy)))\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete epoch 0: 0:00:22.384340\n",
      "Accuracy: 0.013084946980175198\n",
      "Complete epoch 1: 0:00:23.021383\n",
      "Accuracy: 0.029032367615095825\n",
      "Complete epoch 2: 0:00:21.820058\n",
      "Accuracy: 0.047092965817032206\n",
      "Complete epoch 3: 0:00:21.733202\n",
      "Accuracy: 0.05797962770862149\n",
      "Complete epoch 4: 0:00:21.699064\n",
      "Accuracy: 0.07111397204109861\n",
      "Complete epoch 5: 0:00:21.770630\n",
      "Accuracy: 0.08717418329710859\n",
      "Complete epoch 6: 0:00:21.539986\n",
      "Accuracy: 0.09841475663571098\n",
      "Complete epoch 7: 0:00:21.633756\n",
      "Accuracy: 0.09654856583020482\n",
      "Complete epoch 8: 0:00:21.294289\n",
      "Accuracy: 0.11105162846604753\n",
      "Complete epoch 9: 0:00:22.929119\n",
      "Accuracy: 0.11202537377329908\n",
      "Complete epoch 10: 0:00:22.108524\n",
      "Accuracy: 0.1142836560627017\n",
      "Complete epoch 11: 0:00:22.355787\n",
      "Accuracy: 0.11760614256075874\n",
      "Complete epoch 12: 0:00:21.833686\n",
      "Accuracy: 0.12392406392017388\n",
      "Complete epoch 13: 0:00:21.347218\n",
      "Accuracy: 0.13143009451360074\n",
      "Complete epoch 14: 0:00:21.338783\n",
      "Accuracy: 0.11166497892379634\n",
      "Complete epoch 15: 0:00:27.074268\n",
      "Accuracy: 0.13072041921886318\n",
      "Complete epoch 16: 0:00:24.041088\n",
      "Accuracy: 0.12349471859974973\n",
      "Complete epoch 17: 0:00:21.752938\n",
      "Accuracy: 0.1294813689652901\n",
      "Complete epoch 18: 0:00:22.888532\n",
      "Accuracy: 0.14314899888032667\n",
      "Complete epoch 19: 0:00:28.975900\n",
      "Accuracy: 0.1538714145755121\n",
      "Complete epoch 20: 0:00:27.917773\n",
      "Accuracy: 0.13553501448989003\n",
      "Complete epoch 21: 0:00:28.761927\n",
      "Accuracy: 0.1344030947441217\n",
      "Complete epoch 22: 0:00:23.813854\n",
      "Accuracy: 0.13952261575446223\n",
      "Complete epoch 23: 0:00:26.581460\n",
      "Accuracy: 0.14652489626556017\n",
      "Complete epoch 24: 0:00:25.677388\n",
      "Accuracy: 0.14719433330040174\n",
      "Complete epoch 25: 0:00:24.102890\n",
      "Accuracy: 0.14747826516498713\n",
      "Complete epoch 26: 0:00:22.314014\n",
      "Accuracy: 0.14234464532701044\n",
      "Complete epoch 27: 0:00:21.130016\n",
      "Accuracy: 0.14762347279852467\n",
      "Complete epoch 28: 0:00:20.978654\n",
      "Accuracy: 0.15280721036685765\n",
      "Complete epoch 29: 0:00:21.755860\n",
      "Accuracy: 0.15165635496937363\n",
      "Complete epoch 30: 0:00:21.239200\n",
      "Accuracy: 0.15752517206744387\n",
      "Complete epoch 31: 0:00:21.450033\n",
      "Accuracy: 0.14583323042218269\n",
      "Complete epoch 32: 0:00:20.833469\n",
      "Accuracy: 0.15221969060791674\n",
      "Complete epoch 33: 0:00:21.764549\n",
      "Accuracy: 0.15054295923071853\n",
      "Complete epoch 34: 0:00:22.345671\n",
      "Accuracy: 0.160115342817625\n",
      "Complete epoch 35: 0:00:27.466758\n",
      "Accuracy: 0.16092978166370284\n",
      "Complete epoch 36: 0:00:23.511848\n",
      "Accuracy: 0.1547973061977211\n",
      "Complete epoch 37: 0:00:22.255079\n",
      "Accuracy: 0.1615448816110123\n",
      "Complete epoch 38: 0:00:23.150880\n",
      "Accuracy: 0.16023955657643413\n",
      "Complete epoch 39: 0:00:22.690021\n",
      "Accuracy: 0.16307414130935916\n"
     ]
    }
   ],
   "source": [
    "model = train(sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}